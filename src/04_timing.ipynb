{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing for data prep and NN Prox Op calculation\n",
    "\n",
    "Compared to timing for exact prox op function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import time as time\n",
    "import sys\n",
    "import platform, psutil\n",
    "from numba import jit, prange\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from prox_op import prox_op\n",
    "from data_fcns import generate_raw_data, vanilla_scaling, compute_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python version\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get CPU info\n",
    "\n",
    "print(platform.processor())\n",
    "print(platform.machine())\n",
    "print(platform.version())\n",
    "print(platform.platform())\n",
    "print(platform.uname())\n",
    "print(platform.system())\n",
    "print(str(round(psutil.virtual_memory().total / (1024.0 **3)))+\" GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get GPU info\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.cuda.current_device())\n",
    "    print(torch.cuda.device(0))\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_type = \"feature\"  # vanilla or feature\n",
    "data_dist = \"both\"   # norm, unif, or both\n",
    "unif_min = 0\n",
    "unif_max = 1\n",
    "min_len = 100000\n",
    "max_len = 100000\n",
    "num_vec = 10000\n",
    "seed = 1\n",
    "num_moments = 10\n",
    "\n",
    "X, lengths, alphas, taus = generate_raw_data(data_dist, min_len, max_len, num_vec, unif_min, unif_max, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exact Prox Op Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SERIAL\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "PROX_OG = np.zeros(X.shape)\n",
    "for i in range(PROX_OG.shape[0]):\n",
    "    PROX_OG[i,:] = prox_op(X[i,:], alphas[i])[0]\n",
    "\n",
    "t2 = time.perf_counter()    \n",
    "\n",
    "print(f\"Total Time: {t2-t1}\")\n",
    "print(f\"Average Time per Vector: {(t2-t1)/X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def prox_op_jit(x, alpha):\n",
    "    \n",
    "    # same function as prox_op in prox_op.py -- just with a jit decorator\n",
    "    \n",
    "    m = len(x)\n",
    "    \n",
    "    if alpha >= np.linalg.norm(x,1):\n",
    "        tstar = 0\n",
    "        istar = m\n",
    "        prox = np.zeros(x.shape)\n",
    "    else:\n",
    "        # permute x to be in decreasing order in abs value\n",
    "        s = np.sort(np.abs(x))[::-1]\n",
    "        s = np.append(s,0)\n",
    "    \n",
    "        # find value for minimizer    \n",
    "        tstar = 0\n",
    "        istar = m\n",
    "        s_sum = 0\n",
    "        i = 0\n",
    "        while i < m:  # len(x) = m\n",
    "            s_i = s[i]\n",
    "            s_sum = s_sum + s_i\n",
    "            \n",
    "            # check for repeated elements\n",
    "            j = 1\n",
    "            while (i+j < m) and s[i+j] == s_i:  \n",
    "                s_sum = s_sum + s_i\n",
    "                j = j+1\n",
    "            \n",
    "            i = i + (j-1)\n",
    "\n",
    "            t0 = (s_sum - alpha)/(i+1)  # minimizer\n",
    "\n",
    "            if (t0 <= s[i]) and (t0 > s[i+1]): \n",
    "                tstar = t0\n",
    "                istar = i+1\n",
    "                break\n",
    "\n",
    "            i = i+1\n",
    "        # end while\n",
    "        \n",
    "        # compute proximal operator\n",
    "        prox = x.copy()\n",
    "        idx = (np.abs(x) > tstar)\n",
    "        prox[idx] = np.sign(x[idx])*tstar\n",
    "            \n",
    "    return prox, tstar, istar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def compute_prox_op_og_jit(X,pred_tau):\n",
    "    \n",
    "    PROX = np.zeros(X.shape)\n",
    "    for i in prange(PROX.shape[0]):\n",
    "        PROX[i,:] = prox_op_jit(X[i,:], alphas[i])[0]\n",
    "\n",
    "    return PROX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "compute_prox_op_og_jit(X,alphas)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "t3 = time.perf_counter()\n",
    "P0 = compute_prox_op_og_jit(X,alphas)\n",
    "t4 = time.perf_counter()\n",
    "\n",
    "print(f\"Total Time + COMPILATION: {t2-t1}\")\n",
    "print(f\"Average Time per Vector + COMPILATION: {(t2-t1)/X.shape[0]}\")\n",
    "\n",
    "print(f\"Total Time: {t4-t3}\")\n",
    "print(f\"Average Time per Vector: {(t4-t3)/X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.array_equal(PROX_OG, P0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Features NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Features -- TIMED (see below)\n",
    "\n",
    "1. Serial version\n",
    "2. parallel (jit) version -- TIMED\n",
    "3. Checked that the serial and parallel versions give the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SERIAL\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "M2, yhat2, mus2, zero_idx2 = compute_features(X, lengths, alphas, taus, num_moments)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Total Time: {t2-t1}\")\n",
    "print(f\"Average Time per Vector: {(t2-t1)/M2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(zero_idx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def compute_features_jit(X, len_v, alphas, taus, num_moments):\n",
    "\n",
    "    # same function as compute_features in data_fcns.py -- exceptions: 1) uses a jit decorator, \n",
    "    # 2) variable vector length not needed, 3) no need to return yhat \n",
    "    \n",
    "    num_obs = X.shape[0]\n",
    "    M = np.zeros((num_obs, num_moments+3))\n",
    "    #yhat = np.zeros(num_obs)\n",
    "    zero_idx = np.zeros(num_obs)#, dtype=bool)\n",
    "    mus = np.zeros(num_obs)\n",
    "    \n",
    "    for i in prange(num_obs):\n",
    "        \n",
    "        #if i%1000 == 0:\n",
    "        #    print(i)\n",
    "        \n",
    "        #len_v = lengths[i]\n",
    "        x = X[i,:]  # X[i,0:len_v]\n",
    "        alpha = alphas[i]\n",
    "        \n",
    "        w = np.abs(x)/alpha\n",
    "        w_1norm = np.linalg.norm(w,1) \n",
    "\n",
    "        if w_1norm > 1:\n",
    "\n",
    "            mu = w_1norm/len_v\n",
    "            v = w - mu \n",
    "\n",
    "            m = np.zeros(num_moments+3) # min, max, moments, length\n",
    "            m[0] = np.min(v)\n",
    "            m[1] = np.max(v)\n",
    "            m[2] = np.linalg.norm(v,1)/len_v  # L1  \n",
    "\n",
    "            # second moment: sum(x^2)\n",
    "            v_power = np.square(v)\n",
    "            m[3] = np.sqrt( np.sum(v_power)/len_v )\n",
    "\n",
    "            # jth moment: sum(x^i)\n",
    "            for j in range(3, num_moments+1): \n",
    "                v_power = v_power*v  # v^j\n",
    "                mom = np.sum(v_power)/len_v\n",
    "                if j % 2 == 1: # odd moment      \n",
    "                    m[j+1] = np.sign(mom)*np.power(abs(mom), 1/j)\n",
    "                else: # even moment\n",
    "                    m[j+1] = np.power(mom, 1/j)\n",
    "\n",
    "            m[2+num_moments] = np.log(len_v)\n",
    "\n",
    "            M[i,:] = m\n",
    "            \n",
    "            # transform y (tau) \n",
    "            #yhat[i] = (taus[i]/alpha) - mu\n",
    "            \n",
    "            mus[i] = mu\n",
    "        \n",
    "        else:\n",
    "            print(f'Zero index {i}')\n",
    "            zero_idx[i] = True\n",
    "\n",
    "    return M, mus, zero_idx # M, yhat, mus, zero_idx   \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "compute_features_jit(X, min_len, alphas, taus, num_moments)\n",
    "t2 = time.perf_counter()\n",
    "    \n",
    "t3 = time.perf_counter()\n",
    "M, mus, zero_idx = compute_features_jit(X, min_len, alphas, taus, num_moments)\n",
    "t4 = time.perf_counter()\n",
    "    \n",
    "print(f\"Total Time + COMPILATION: {t2-t1}\")\n",
    "print(f\"Average Time per Vector + COMPILATION: {(t2-t1)/M.shape[0]}\")\n",
    "\n",
    "t_compute_feat = t4-t3\n",
    "print(f\"Total Time: {t4-t3}\")\n",
    "print(f\"Average Time per Vector: {(t4-t3)/M.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(zero_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if the parallel and serial versions of feature computation are equal - YES\n",
    "\n",
    "print(np.array_equal(M, M2))\n",
    "#print(np.array_equal(yhat, yhat2))\n",
    "print(np.array_equal(mus, mus2))\n",
    "print(np.array_equal(zero_idx, zero_idx2))\n",
    "\n",
    "print(np.allclose(M, M2))\n",
    "#print(np.allclose(yhat, yhat2))\n",
    "print(np.allclose(mus, mus2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mus-mus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M-M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any observations from dataset that have tau = 0 -- NOT NEEDED FOR TIMED VERSIONS\n",
    "# if there are zeros in the dataset, use a different dataset\n",
    "\n",
    "#zero_idx = zero_idx.astype(bool)\n",
    "\n",
    "if sum(zero_idx) > 0:\n",
    "    \n",
    "    M = M[~zero_idx,:]\n",
    "    #yhat = yhat[~zero_idx]\n",
    "    mus = mus[~zero_idx]\n",
    "    alphas = alphas[~zero_idx]\n",
    "    taus = taus[~zero_idx]\n",
    "    \n",
    "    # for compute prox ops\n",
    "    X = X[~zero_idx,:]\n",
    "    #lengths = lengths[~zero_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(zero_idx) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first layer number of inputs\n",
    "device = \"cpu\"\n",
    "layer1_size = M[0].shape[0]\n",
    "layer1_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set NN based on layer1_size\n",
    "\n",
    "if layer1_size == (num_moments+3):  # features NN\n",
    "    \n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(num_moments+3, 25),  \n",
    "                nn.ReLU(),    \n",
    "                nn.Linear(25, 10),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(10, 1)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            tau = self.linear_relu_stack(x) \n",
    "            return tau\n",
    "        \n",
    "elif (layer1_size == 2000) or (layer1_size == 100000):   # vanilla NN\n",
    "    \n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(layer1_size, 200),   \n",
    "                nn.ReLU(),  \n",
    "                nn.Linear(200, 100),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(100, 50), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(50, 1) \n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            tau = self.linear_relu_stack(x)\n",
    "            return tau\n",
    "    \n",
    "else:\n",
    "    pass\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model = NeuralNetwork()\n",
    "#model.load_state_dict(torch.load(\"models/features/gaussian/len_1000_2000/epoch_4421_nn.pt\"))\n",
    "#model.load_state_dict(torch.load(\"models/features/gaussian/len_1000_100000/epoch_4695_nn.pt\"))\n",
    "#model.load_state_dict(torch.load(\"models/features/uniform_0_1/len_1000_2000/epoch_4897_nn.pt\"))\n",
    "#model.load_state_dict(torch.load(\"models/features/uniform_0_1/len_1000_100000/epoch_4928_nn.pt\"))\n",
    "#model.load_state_dict(torch.load(\"models/features/both/len_1000_2000/epoch_4570_nn.pt\"))\n",
    "model.load_state_dict(torch.load(\"models/features/both/len_1000_100000/epoch_4792_nn.pt\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Inference -- TIMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    t1 = time.perf_counter()\n",
    "    pred_tau_hat = model(torch.Tensor(M))\n",
    "    t2 = time.perf_counter()\n",
    "\n",
    "t_nn_inf = t2-t1\n",
    "print(f\"Total Time: {t2-t1}\")\n",
    "print(f\"Average Time per Vector: {(t2-t1)/M.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time tau and prox op computations\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "# transform tau back: tau = alpha(tau_hat + mu)\n",
    "pred_tau_hat = pred_tau_hat.squeeze().numpy()\n",
    "pred_tau = np.add(pred_tau_hat, mus)    \n",
    "pred_tau = np.multiply(alphas, pred_tau)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "t_tau_from_tauhat = t2-t1\n",
    "print(f\"Total Time: {t2-t1}\")\n",
    "print(f\"Average Time per Vector: {(t2-t1)/M.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Prox Op with Predicted Taus -- TIMED\n",
    "\n",
    "1. serial version\n",
    "2. parallel (jit) version -- TIMED\n",
    "3. Check that serial and parallel versions give the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SERIAL\n",
    "\n",
    "def compute_prox_op(X,pred_tau):\n",
    "    \n",
    "    PROX = np.copy(X)\n",
    "    \n",
    "    for i in range(PROX.shape[0]):\n",
    "        idx = (np.abs(X[i,:]) > pred_tau[i])\n",
    "        PROX[i,idx] = np.sign(X[i,idx])*pred_tau[i]\n",
    "\n",
    "    return PROX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def compute_prox_op_jit(X,pred_tau):\n",
    "    \n",
    "    PROX = np.zeros(X.shape)\n",
    "    \n",
    "    for i in prange(PROX.shape[0]):\n",
    "        PROX[i,:] = X[i,:].copy()\n",
    "        idx = (np.abs(X[i,:]) > pred_tau[i])\n",
    "        PROX[i,idx] = np.sign(X[i,idx])*pred_tau[i]\n",
    "\n",
    "    return PROX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t5 = time.perf_counter()\n",
    "P2 = compute_prox_op(X,pred_tau)\n",
    "t6 = time.perf_counter()\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "compute_prox_op_jit(X,pred_tau)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "t3 = time.perf_counter()\n",
    "P = compute_prox_op_jit(X,pred_tau)\n",
    "t4 = time.perf_counter()\n",
    "\n",
    "t_prox_op = t4-t3\n",
    "\n",
    "print(f\"SERIAL Total Time: {t6-t5}\")\n",
    "print(f\"SERIAL Average Time per Vector: {(t6-t5)/M.shape[0]}\")\n",
    "\n",
    "print(f\"Total Time + COMPILATION: {t2-t1}\")\n",
    "print(f\"Average Time per Vector + COMPILATION: {(t2-t1)/M.shape[0]}\")\n",
    "\n",
    "print(f\"Total Time: {t4-t3}\")\n",
    "print(f\"Average Time per Vector: {(t4-t3)/M.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the parallel and serial versions of feature computation are equal - YES\n",
    "\n",
    "print(np.array_equal(P, P2))\n",
    "print(np.allclose(P, P2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate total prox op time\n",
    "\n",
    "1. compute tau from tau_hat\n",
    "2. compute prox op with tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_temp = t_tau_from_tauhat + t_prox_op\n",
    "\n",
    "print(f\"Prox Op Time: {t_temp}\")\n",
    "print(f\"Average Time per Vector: {t_temp/M.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_total = t_compute_feat + t_nn_inf + t_tau_from_tauhat + t_prox_op\n",
    "\n",
    "print(f\"Total Time: {t_total}\")\n",
    "print(f\"Average Time per Vector: {t_total/M.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_compute_feat/M.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_nn_inf/M.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
